{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base path: /mnt/ssd-1/mechinterp/taras/Count_PIPNet\n"
     ]
    }
   ],
   "source": [
    "# Enable auto-reloading of imports when they have been modified\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython(); assert ipython is not None\n",
    "ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "ipython.run_line_magic(\"autoreload\", \"2\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Disable gradient computation - this notebook will only perform forward passes\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the base (root) directory to the path so we can import the util modules\n",
    "def get_base_folder(project_root = \"Count_PIPNet\"):\n",
    "\t# Find the project root dynamically\n",
    "\tcurrent_dir = os.getcwd()\n",
    "\twhile True:\n",
    "\t\tif os.path.basename(current_dir) == project_root:  # Adjust to match your project root folder name\n",
    "\t\t\tbreak\n",
    "\t\tparent = os.path.dirname(current_dir)\n",
    "\t\tif parent == current_dir:  # Stop if we reach the system root (failsafe)\n",
    "\t\t\traise RuntimeError(f\"Project root {project_root} not found. Check your folder structure.\")\n",
    "\t\tcurrent_dir = parent\n",
    "\n",
    "\treturn Path(current_dir)\n",
    "\n",
    "base_path = get_base_folder()\n",
    "print(f\"Base path: {base_path}\")\n",
    "sys.path.append(str(base_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.vis_pipnet import visualize_topk\n",
    "from pipnet.count_pipnet import get_count_network\n",
    "from util.checkpoint_manager import CheckpointManager\n",
    "from util.data import get_dataloaders\n",
    "from util.args import get_args\n",
    "from util.vis_pipnet import visualize_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Using cuda:3 device <<<\n"
     ]
    }
   ],
   "source": [
    "# Device setup\n",
    "GPU_TO_USE = 3\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = f\"cuda:{GPU_TO_USE}\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f'>>> Using {device} device <<<')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/ssd-1/mechinterp/taras/Count_PIPNet/runs/stage_3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_experiment_dir = base_path / 'runs/stage_3'\n",
    "multi_experiment_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_dir = base_path / 'visualizations'\n",
    "os.makedirs(visualization_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 trained models\n"
     ]
    }
   ],
   "source": [
    "summary_path = os.path.join(multi_experiment_dir, 'summary.json')\n",
    "\n",
    "# Load the summary file to get all run directories\n",
    "with open(summary_path, 'r') as f:\n",
    "    summary = json.load(f)\n",
    "\n",
    "print(f\"Found {len(summary)} trained models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(run_dir, checkpoint_name='net_trained_best', base_path=base_path, gpu_id=3):\n",
    "\t\"\"\"\n",
    "\tLoad a model from a checkpoint directory for visualization purposes.\n",
    "\n",
    "\tArgs:\n",
    "\t\trun_dir: Directory containing the run results\n",
    "\t\tcheckpoint_name: Name of checkpoint to load (default: 'net_trained_best')\n",
    "\t\tbase_path: Base path for dataset directories (default: None)\n",
    "\t\tgpu_id: GPU ID to use (default: 0)\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t\tTuple of (net, projectloader, classes, args, is_count_pipnet)\n",
    "\t\"\"\"\n",
    "\t# Step 1: Load the configuration used for this run\n",
    "\tmetadata_dir = os.path.join(run_dir, 'metadata')\n",
    "\targs_path = os.path.join(metadata_dir, 'args.pickle')\n",
    "\n",
    "\timport pickle\n",
    "\twith open(args_path, 'rb') as f:\n",
    "\t\targs = pickle.load(f)\n",
    "\tprint(f\"Loaded configuration from {args_path}\")\n",
    "\n",
    "\t# Explicitly set GPU ID to ensure device consistency\n",
    "\tif torch.cuda.is_available():\n",
    "\t\targs.gpu_ids = str(gpu_id)\n",
    "\t\tdevice = torch.device(f'cuda:{gpu_id}')\n",
    "\t\ttorch.cuda.set_device(device)\n",
    "\telse:\n",
    "\t\tdevice = torch.device('cpu')\n",
    "\n",
    "\tprint(f\"Using device: {device}\")\n",
    "\n",
    "\t# Step 2: Create dataloaders (needed for projectloader)\n",
    "\targs.log_dir = run_dir  # Use the run directory as log_dir\n",
    "\ttrainloader, trainloader_pretraining, trainloader_normal, \\\n",
    "\ttrainloader_normal_augment, projectloader, testloader, test_projectloader, classes = get_dataloaders(args, device, base_path)\n",
    "\n",
    "\t# Step 3: Create a model with the same architecture\n",
    "\tif hasattr(args, 'model') and args.model == 'count_pipnet':\n",
    "\t\tis_count_pipnet = True\n",
    "\t\tnet, num_prototypes = get_count_network(\n",
    "\t\t\tnum_classes=len(classes), \n",
    "\t\t\targs=args,\n",
    "\t\t\tmax_count=getattr(args, 'max_count', 3),\n",
    "\t\t\tuse_ste=getattr(args, 'use_ste', False))\n",
    "\telse:\n",
    "\t\tfrom pipnet.pipnet import get_pipnet\n",
    "\t\tis_count_pipnet = False\n",
    "\t\tnet, num_prototypes = get_pipnet(len(classes), args)\n",
    "\n",
    "\t# Step 4: Move model to device (don't use DataParallel yet)\n",
    "\tnet = net.to(device)\n",
    "\n",
    "\t# Step 5: Forward one batch through the backbone to get the latent output size\n",
    "\t# This needs to happen BEFORE loading the checkpoint\n",
    "\twith torch.no_grad():\n",
    "\t\t# Use a small batch to determine output shape\n",
    "\t\txs1, _, _ = next(iter(trainloader))\n",
    "\t\txs1 = xs1.to(device)\n",
    "\n",
    "\t\t# Single-forward pass without DataParallel\n",
    "\t\tfeatures = net._net(xs1)\n",
    "\t\tproto_features = net._add_on(features)\n",
    "\n",
    "\t\twshape = proto_features.shape[-1]\n",
    "\t\targs.wshape = wshape  # needed for calculating image patch size\n",
    "\t\tprint(f\"Output shape: {proto_features.shape}, setting wshape={wshape}\")\n",
    "            \n",
    "\t# Step 6: Now wrap with DataParallel\n",
    "\tdevice_ids = [gpu_id]\n",
    "\tprint(f\"Using device_ids: {device_ids}\")\n",
    "\tnet = nn.DataParallel(net, device_ids=device_ids)\n",
    "\n",
    "\t# Step 7: Direct checkpoint loading\n",
    "\tcheckpoint_path = os.path.join(run_dir, 'checkpoints', checkpoint_name)\n",
    "\tif not os.path.exists(checkpoint_path):\n",
    "\t\tprint(f\"Checkpoint not found at {checkpoint_path}, trying alternative paths...\")\n",
    "\t\t# Try with full path as fallback\n",
    "\t\tif os.path.exists(checkpoint_name):\n",
    "\t\t\tcheckpoint_path = checkpoint_name\n",
    "\t\telse:\n",
    "\t\t\t# Try other common checkpoint names\n",
    "\t\t\talternatives = [\n",
    "\t\t\t\tos.path.join(run_dir, 'checkpoints', 'net_trained_last'),\n",
    "\t\t\t\tos.path.join(run_dir, 'checkpoints', 'net_trained')\n",
    "\t\t\t]\n",
    "\t\t\tfor alt_path in alternatives:\n",
    "\t\t\t\tif os.path.exists(alt_path):\n",
    "\t\t\t\t\tcheckpoint_path = alt_path\n",
    "\t\t\t\t\tprint(f\"Found alternative checkpoint at {checkpoint_path}\")\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"No checkpoint found\")\n",
    "\t\t\t\treturn None, None, None, None, None\n",
    "\n",
    "\ttry:\n",
    "\t\t# Load just the model state dict, ignore optimizer states\n",
    "\t\tcheckpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\t\t\n",
    "\t\tif 'model_state_dict' in checkpoint:\n",
    "\t\t\tnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "\t\t\tprint(f\"Successfully loaded model state from {checkpoint_path}\")\n",
    "\t\t\t\n",
    "\t\t\t# Display additional information if available\n",
    "\t\t\tif 'epoch' in checkpoint:\n",
    "\t\t\t\tprint(f\"Checkpoint from epoch {checkpoint['epoch']}\")\n",
    "\t\t\tif 'accuracy' in checkpoint:\n",
    "\t\t\t\tprint(f\"Model accuracy: {checkpoint['accuracy']:.4f}\")\n",
    "\t\t\t\n",
    "\t\t\treturn net, projectloader, classes, args, is_count_pipnet\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"Checkpoint doesn't contain model_state_dict\")\n",
    "\t\t\treturn None, None, None, None, None\n",
    "\t\t\t\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error loading checkpoint: {str(e)}\")\n",
    "\t\timport traceback\n",
    "\t\ttraceback.print_exc()\n",
    "\t\treturn None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'run_index': 1,\n",
       "  'config_path': 'configs/full_linear.yaml',\n",
       "  'status': 'completed',\n",
       "  'duration': 1631.151186466217,\n",
       "  'log_dir': './runs/stage_3/20250401_071214_1_full_linear'},\n",
       " {'run_index': 2,\n",
       "  'config_path': 'configs/identity.yaml',\n",
       "  'status': 'completed',\n",
       "  'duration': 1676.0133264064789,\n",
       "  'log_dir': './runs/stage_3/20250401_073925_2_identity'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a checkpoint from /mnt/ssd-1/mechinterp/taras/Count_PIPNet/runs/stage_3/20250401_064200_0_linear...\n"
     ]
    }
   ],
   "source": [
    "checkpoint_to_load = '20250401_064200_0_linear'\n",
    "path_to_load = multi_experiment_dir / checkpoint_to_load\n",
    "\n",
    "print(f'Loading a checkpoint from {path_to_load}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configuration from /mnt/ssd-1/mechinterp/taras/Count_PIPNet/runs/stage_3/20250401_064200_0_linear/metadata/args.pickle\n",
      "Using device: cuda:3\n",
      "Num classes (k) =  9 ['class_1', 'class_2', 'class_3', 'class_4', 'class_5'] etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 192 output channels from last conv layer\n",
      "Number of prototypes set from 192 to 16. Extra 1x1 conv layer added.\n",
      "Output shape: torch.Size([64, 16, 24, 24]), setting wshape=24\n",
      "Using device_ids: [3]\n",
      "Successfully loaded model state from /mnt/ssd-1/mechinterp/taras/Count_PIPNet/runs/stage_3/20250401_064200_0_linear/checkpoints/net_trained_best\n",
      "Checkpoint from epoch 93\n",
      "Model accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "net, projectloader, classes, args, is_count_pipnet = load_model(path_to_load, gpu_id=GPU_TO_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving viz to /mnt/ssd-1/mechinterp/taras/Count_PIPNet/visualizations/20250401_064200_0_linear\n"
     ]
    }
   ],
   "source": [
    "run_vis_dir = visualization_dir /checkpoint_to_load\n",
    "\n",
    "print(f'Saving viz to {run_vis_dir}')\n",
    "\n",
    "os.makedirs(run_vis_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing prototypes for topk (CountPIPNet with class-based count selection)...\n",
      "Using class-to-count mapping: {(1, 3): 1, (4, 6): 2, (7, 9): 3}\n",
      "Available counts: [1, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting activations:   0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting activations:  28%|██▊       | 1000/3600 [00:03<00:08, 295.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected model type: CountPIPNet with max_count=3\n",
      "Visualizing trained prototypes\n",
      "Examples per count group: 10\n",
      "Pooled shape: torch.Size([16]), min: 0.0, max: 555.0\n",
      "Feature maps shape: torch.Size([16, 24, 24])\n",
      "Non-zero pooled values: 4 out of 16\n",
      "Pooled values (counts): [8.0, 12.0, 0.0, 0.0, 0.0, 0.0, 555.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Classification weights shape: torch.Size([9, 48]) (expanded)\n",
      "Max classification weight per prototype: [3.101, 0.0, 0.3846, 8.6222, 0.0, 2.9144, 0.0, 9.6965, 0.1289, 0.0, 7.7373, 4.1335, 2.0769, 2.0048, 2.435, 3.9396]\n",
      "Prototypes with weight > 1e-3: 12\n",
      "Prototype indices with weight > 1e-3: [0, 2, 3, 5, 7, 8, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Single-pass processing for class-based count selection: 100% 3600/3600 [00:16<00:00, 223.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained: 0\n",
      "0 prototypes do not have any examples. Will be ignored in visualization.\n",
      "Creating prototype feature map visualizations with count information...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to /mnt/ssd-1/mechinterp/taras/Count_PIPNet/visualizations/20250401_064200_0_linear\n"
     ]
    }
   ],
   "source": [
    "topks = visualize_topk(net, projectloader, len(classes), device, run_vis_dir, args, k=10,\n",
    "\t\t\t\t\t   plot_histograms=True, visualize_prototype_maps=True)\n",
    "print(f\"Visualization saved to {run_vis_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many prototypes are used by each class\n",
    "class_prototypes = {}\n",
    "for c in range(net.module._classification.weight.shape[0]):\n",
    "\trelevant_ps = []\n",
    "\tproto_weights = net.module._classification.weight[c,:]\n",
    "\tfor p in range(net.module._classification.weight.shape[1]):\n",
    "\t\tif proto_weights[p] > 1e-3:\n",
    "\t\t\trelevant_ps.append((p, proto_weights[p].item()))\n",
    "\t\n",
    "\tclass_name = classes[c] if c < len(classes) else f\"Class {c}\"\n",
    "\tclass_prototypes[class_name] = relevant_ps\n",
    "\tprint(f\"Class {class_name} has {len(relevant_ps)} relevant prototypes\")\n",
    "\t\n",
    "# Save class-prototype information\n",
    "class_info_path = os.path.join(run_vis_dir, 'class_prototypes.json')\n",
    "with open(class_info_path, 'w') as f:\n",
    "\tjson.dump(class_prototypes, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taras_ami",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
