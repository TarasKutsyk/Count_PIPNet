# CountPIPNet MNIST Configuration
model: count_pipnet               # Model type: 'pipnet' for original or 'count_pipnet' for counting-aware version
dataset: mnist_counting           # Dataset name as defined in data.py

max_count: 3                      # Maximum count value to track; counts >= max_count get mapped to max_count category
use_ste: False                     # Whether to use Straight-Through Estimator for count discretization during training
use_mid_layers: True              # Use only middle layers of the backbone network
num_stages: 3                     # Number of stages to use when using middle layers
num_features: 16                   # Number of prototypes (0 = use backbone's output channel count)

# Network architecture
net: convnext_tiny_26             # Backbone CNN architecture; 26 indicates output feature map size
image_size: 192                    # Input image resolution (height and width)
disable_pretrained: False         # When False, uses weights pretrained on ImageNet

# Training parameters
batch_size: 32                    # Batch size for main training phase
batch_size_pretrain: 64           # Batch size for prototype pretraining phase
epochs: 30                        # Number of training epochs (main phase)
epochs_pretrain: 10               # Number of prototype pretraining epochs
freeze_epochs: 8                 # Number of epochs to keep early backbone layers frozen

# Optimization parameters
optimizer: Adam                   # Optimization algorithm for updating weights
lr: 0.05                          # Learning rate for classification layer
lr_block: 0.0005                  # Learning rate for middle backbone layers
lr_net: 0.0005                    # Learning rate for early backbone layers
weight_decay: 0.0                 # L2 regularization strength (0.0 = no regularization)

# Logging and output
log_dir: ./runs/count_pipnet_mnist # Directory for saving logs and checkpoints
dir_for_saving_images: visualization_results_mnist # Directory for prototype visualizations

# Other parameters
validation_size: 0.0              # Fraction of training data to use for validation (0.0 = use separate test set)
weighted_loss: False              # Whether to weight loss by inverse class frequency
seed: 1                           # Random seed for reproducibility
gpu_ids: '0'                      # GPU IDs to use (comma-separated for multiple GPUs)
num_workers: 20                    # Number of CPU threads for data loading
bias: False                       # Whether to use bias terms in classification layer
disable_cuda: False               # When True, forces CPU usage even if GPU is available